import pandas as pd
import re
import os
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
import nltk
from nltk.corpus import stopwords

# Download NLTK resources
# nltk.download('stopwords')
current_directory = os.getcwd()  # Get current working directory
file_path = os.path.join(current_directory, 'drug.csv')  # Construct the file path
df = pd.read_csv(file_path)
# Read the drug review dataset (drug_reviews.csv)
# df = pd.read_csv('drug_reviews.csv')

# Data preprocessing and cleaning
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = BeautifulSoup(text, 'html.parser').get_text()  # Remove HTML tags
    text = re.sub(r"[^a-zA-Z]", " ", text)  # Remove non-alphabetic characters
    words = text.lower().split()  # Convert to lowercase and split into words
    words = [w for w in words if w not in stop_words]  # Remove stopwords
    return " ".join(words)

df['clean_review'] = df['review'].apply(clean_text)

# Convert ratings to sentiment labels: Positive (1), Neutral (0), Negative (-1)
df['sentiment'] = df['rating'].apply(lambda x: 1 if x > 3 else (-1 if x < 3 else 0))

# Split data into features (X) and labels (y)
X = df['clean_review']
y = df['sentiment']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize text data using CountVectorizer
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Train a Naive Bayes classifier
classifier = MultinomialNB()
classifier.fit(X_train_vectorized, y_train)

predictions = classifier.predict(X_test_vectorized)

# Evaluate the classifier
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_test, predictions))
# Sample usage of the trained model with top 3 recommendations
def predict_sentiment_with_recommendations(review_text):
    cleaned_text = clean_text(review_text)
    vectorized_text = vectorizer.transform([cleaned_text])
    sentiment_label = classifier.predict(vectorized_text)[0]
    if sentiment_label == 1:
        sentiment = "Positive"
    elif sentiment_label == 0:
        sentiment = "Neutral"
    else:
        sentiment = "Negative"

    # Extract top 3 recommendations based on the predicted sentiment
    target_condition = "Positive" if sentiment_label == 1 else "Negative" if sentiment_label == -1 else "Neutral"
    top_recommendations = df[(df['sentiment'] == sentiment_label) & (df['rating'] > 3)].nlargest(3, 'rating')['drugName'].tolist()

    return sentiment, top_recommendations

# Example usage
sample_review = "This medication worked wonders for my condition. I highly recommend it."
predicted_sentiment, top_recommendations = predict_sentiment_with_recommendations(sample_review)
print("Predicted Sentiment:", predicted_sentiment)
print(sample_review)
print("Top 3 Recommendations:")
print(top_recommendations)

sample_review = "I have only been on Tekturna for 9 days.The effect was immediate. I am also on a calcium channel blocker (Tiazac) and hydrochlorothiazide. I was put on Tekturna because of palpitations experienced with Diovan (ugly drug in my opinion, same company produces both however). The palpitations were pretty bad on Diovan, 24 hour monitor by EKG etc. After a few days of substituting Tekturna for Diovan, there are no more palpitations"
predicted_sentiment, top_recommendations = predict_sentiment_with_recommendations(sample_review)
print("Predicted Sentiment:", predicted_sentiment)
print(sample_review)
print("Top 3 Recommendations:")
print(top_recommendations)


